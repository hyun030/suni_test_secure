# -*- coding: utf-8 -*-
import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta
import json
from typing import List, Dict, Optional

class GoogleNewsCollector:
    """Google News APIë¥¼ í™œìš©í•œ ì •ìœ  ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.search_url = "https://google.serper.dev/news"
        
        # ì •ìœ  ê´€ë ¨ í‚¤ì›Œë“œ ì„¤ì •
        self.company_keywords = ["SKì—ë„ˆì§€", "S-Oil", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "GSì¹¼í…ìŠ¤"]
        self.industry_keywords = ["ì •ìœ ", "ì •ìœ ì—…ê³„", "ì •ìœ ì‚¬", "ì„ìœ í™”í•™", "ì„ìœ í™”í•™ì‚¬"]
        self.business_keywords = ["ì˜ì—…ì´ìµ", "ì‹¤ì ", "ìˆ˜ìµì„±", "íˆ¬ì", "ë§¤ì¶œ", "ì†ì‹¤", "ì •ì œë§ˆì§„"]
        
    def collect_news(self, query: str, num_results: int = 100) -> pd.DataFrame:
        """Google News APIë¥¼ í†µí•´ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        headers = {
            "X-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ì •ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ë‹¨ìˆœí™”)
        clean_query = query.replace('"', '').replace('(', '').replace(')', '')
        
        payload = {
            "q": clean_query,
            "num": min(num_results, 100),  # API ì œí•œ
            "gl": "kr",  # í•œêµ­ ì§€ì—­ ì„¤ì •
            "hl": "ko"   # í•œêµ­ì–´ ê²°ê³¼
        }
        
        try:
            response = requests.post(self.search_url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 400:
                st.error(f"API ìš”ì²­ ì‹¤íŒ¨: ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë‹¨ìˆœí™”í•´ë³´ì„¸ìš”.")
                return pd.DataFrame()
            elif response.status_code != 200:
                st.error(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
                return pd.DataFrame()
            
            data = response.json()
            news_data = data.get("news", [])
            if not news_data:
                st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # DataFrame ë³€í™˜ ë° ì „ì²˜ë¦¬
            df = pd.DataFrame(news_data)
            df = self._preprocess_news_data(df)
            
            return df
            
        except requests.exceptions.RequestException as e:
            st.error(f"API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return pd.DataFrame()
        except Exception as e:
            st.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame()
    
    def _preprocess_news_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬"""
        if df.empty:
            return df
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        required_columns = ["title", "link", "date", "snippet"]
        available_columns = [col for col in required_columns if col in df.columns]
        
        if not available_columns:
            return df
        
        df = df[available_columns].copy()
        
        # ì»¬ëŸ¼ëª… í•œê¸€í™”
        column_mapping = {
            "title": "ì œëª©",
            "link": "URL",
            "date": "ë‚ ì§œ",
            "snippet": "ìš”ì•½"
        }
        df = df.rename(columns=column_mapping)
        
        # ë‚ ì§œ ì „ì²˜ë¦¬ (URLì—ì„œ ìë™ ì¶”ì¶œ)
        if "ë‚ ì§œ" in df.columns:
            df["ë‚ ì§œ"] = df.apply(self._extract_date_from_url, axis=1)
        
        # ìš”ì•½ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì œëª©ìœ¼ë¡œ ëŒ€ì²´
        if "ìš”ì•½" not in df.columns:
            df["ìš”ì•½"] = df["ì œëª©"]
        
        # URL ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
        if "URL" not in df.columns:
            df["URL"] = ""
        
        # íšŒì‚¬ ì»¬ëŸ¼ ì¶”ê°€ (ì œëª©ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ)
        df["íšŒì‚¬"] = df["ì œëª©"].apply(self._extract_company_from_title)
        
        # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        if "ë‚ ì§œ" in df.columns:
            df = df.sort_values("ë‚ ì§œ", ascending=False).reset_index(drop=True)
        else:
            df = df.reset_index(drop=True)
        
        return df
    
    def _extract_date_from_url(self, row):
        """URLì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œ"""
        url = str(row.get("URL", ""))
        date = str(row.get("ë‚ ì§œ", ""))
        
        # 1. ê¸°ì¡´ ë‚ ì§œê°€ ìœ íš¨í•˜ë©´ ì‚¬ìš©
        if date and date != "None" and date != "nan":
            try:
                parsed_date = pd.to_datetime(date, errors="coerce")
                if pd.notna(parsed_date):
                    return parsed_date.strftime("%Y-%m-%d")
            except:
                pass
        
        # 2. URLì—ì„œ ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
        import re
        
        # ë‹¤ì–‘í•œ ë‚ ì§œ íŒ¨í„´
        patterns = [
            r'/(\d{4})/(\d{2})/(\d{2})/',  # /2024/08/12/
            r'(\d{4})-(\d{2})-(\d{2})',    # 2024-08-12
            r'(\d{4})\.(\d{2})\.(\d{2})',  # 2024.08.12
            r'(\d{4})_(\d{2})_(\d{2})',    # 2024_08_12
            r'(\d{4})(\d{2})(\d{2})',      # 20240812
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                if len(match.groups()) == 3:
                    year, month, day = match.groups()
                    try:
                        return f"{year}-{month}-{day}"
                    except:
                        continue
        
        return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
    
    def _extract_company_from_title(self, title: str) -> str:
        """ì œëª©ì—ì„œ íšŒì‚¬ëª…ì„ ì¶”ì¶œí•˜ëŠ” ë©”ì„œë“œ"""
        if not title:
            return "íšŒì‚¬ ë¶ˆëª…"
        
        # ì£¼ìš” ì •ìœ ì‚¬ íšŒì‚¬ëª… ë§¤ì¹­
        company_keywords = {
            "SKì—ë„ˆì§€": ["SKì—ë„ˆì§€", "SKì—ë„ˆ", "SK"],
            "S-Oil": ["S-Oil", "ì—ì“°ì˜¤ì¼", "ì—ì“°-ì˜¤ì¼"],
            "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬": ["HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "í˜„ëŒ€ì˜¤ì¼"],
            "GSì¹¼í…ìŠ¤": ["GSì¹¼í…ìŠ¤", "GSì¹¼", "ì¹¼í…ìŠ¤"]
        }
        
        title_lower = title.lower()
        for company, keywords in company_keywords.items():
            if any(keyword.lower() in title_lower for keyword in keywords):
                return company
        
        # íšŒì‚¬ëª…ì´ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°
        return "ê¸°íƒ€"
    
    def generate_search_queries(self) -> List[str]:
        """ì •ìœ  ê´€ë ¨ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        queries = [
            "SKì—ë„ˆì§€ ì •ìœ ",
            "S-Oil ì •ìœ ",
            "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ ì •ìœ ",
            "GSì¹¼í…ìŠ¤ ì •ìœ ",
            "ì •ìœ ì—…ê³„ SKì—ë„ˆì§€",
            "ì„ìœ í™”í•™ SKì—ë„ˆì§€",
            "ì •ìœ ì‚¬ ì˜ì—…ì´ìµ",
            "ì •ìœ ì‚¬ ì‹¤ì "
        ]
        return queries

def create_google_news_tab():
    """Google News ìˆ˜ì§‘ íƒ­ ìƒì„±"""
    st.subheader("ğŸ” ì •ìœ  ì—…ê³„ ê´€ë ¨ Google ë‰´ìŠ¤ ìˆ˜ì§‘")
    st.info("ğŸ’¡ Google News APIë¥¼ í†µí•´ ì •ìœ  ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ë¶„ì„ ìƒíƒœ í‘œì‹œ
    if hasattr(st.session_state, 'google_news_data') and st.session_state.google_news_data is not None:
        st.success(f"âœ… Google News ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(st.session_state.google_news_data)}ê°œ ë‰´ìŠ¤")
    
    # configì—ì„œ API í‚¤ ìë™ ê°€ì ¸ì˜¤ê¸°
    try:
        import config
        api_key = config.GOOGLE_NEWS_API_KEY
        st.success("âœ… API í‚¤ê°€ ìë™ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")
    except:
        st.error("âŒ config.pyì—ì„œ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if api_key:
        st.session_state.google_news_api_key = api_key
        
        # ê²€ìƒ‰ ì„¤ì •
        col1, col2 = st.columns([2, 1])
        
        with col1:
            search_query = st.text_input(
                "ê²€ìƒ‰ ì¿¼ë¦¬",
                value='SKì—ë„ˆì§€ S-Oil HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ GSì¹¼í…ìŠ¤ ì •ìœ  ì„ìœ í™”í•™',
                help="ê²€ìƒ‰ì–´ë¥¼ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: SKì—ë„ˆì§€ ì •ìœ )"
            )
        
        with col2:
            num_results = st.number_input(
                "ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜",
                min_value=10,
                max_value=200,
                value=100,
                step=10
            )
        
        # ë¯¸ë¦¬ ì •ì˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ì„ íƒ
        st.markdown("**ğŸ“‹ ì¶”ì²œ ê²€ìƒ‰ ì¿¼ë¦¬**")
        collector = GoogleNewsCollector(api_key)
        recommended_queries = collector.generate_search_queries()
        
        selected_query = st.selectbox(
            "ì¶”ì²œ ì¿¼ë¦¬ ì„ íƒ",
            recommended_queries,
            help="ë¯¸ë¦¬ ì •ì˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ì¤‘ì—ì„œ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        )
        
        if st.button("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", type="primary"):
            if not search_query.strip():
                st.error("ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return
            
            with st.spinner("ğŸ”„ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì§„í–‰ ì¤‘..."):
                try:
                    collector = GoogleNewsCollector(api_key)
                    news_df = collector.collect_news(search_query, num_results)
                    
                    if not news_df.empty:
                        # AI ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ)
                        try:
                            from insight.openai_api import OpenAIInsightGenerator
                            import config
                            
                            # OpenAI ì¸ì‚¬ì´íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
                            openai = OpenAIInsightGenerator(config.OPENAI_API_KEY)
                            
                            # ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„± (ìë™)
                            insight = openai.generate_news_insight(news_df)
                            
                            if insight:
                                st.session_state.google_news_insight = insight
                            else:
                                st.error("âŒ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                
                        except Exception as e:
                            st.error(f"âŒ AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        
                        # ì„¸ì…˜ì— ë°ì´í„° ì €ì¥
                        st.session_state.google_news_data = news_df
                        st.session_state.google_news_query = search_query
                        st.session_state.google_news_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        
                        st.success(f"âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ë¶„ì„ ì™„ë£Œ! ì´ {len(news_df)}ê°œ ë‰´ìŠ¤")
                    else:
                        st.error("âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ì™€ ê²€ìƒ‰ì–´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        
                except Exception as e:
                    st.error(f"âŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    # ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ (ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ)
    if hasattr(st.session_state, 'google_news_data') and st.session_state.google_news_data is not None:
        st.markdown("---")
        st.subheader("ğŸ“Š ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ëª©ë¡")
        
        # ìˆ˜ì§‘ ì •ë³´ í‘œì‹œ
        if hasattr(st.session_state, 'google_news_timestamp'):
            st.info(f"ğŸ“… ìˆ˜ì§‘ ì‹œê°„: {st.session_state.google_news_timestamp}")
        if hasattr(st.session_state, 'google_news_query'):
            st.info(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {st.session_state.google_news_query}")
        
        # íšŒì‚¬ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í‘œì‹œì— í¬í•¨
        display_columns = ["ì œëª©", "URL", "ë‚ ì§œ", "ìš”ì•½"]
        if "íšŒì‚¬" in st.session_state.google_news_data.columns:
            display_columns.insert(1, "íšŒì‚¬")
        
        st.dataframe(
            st.session_state.google_news_data[display_columns],
            use_container_width=True,
            column_config={
                "ì œëª©": st.column_config.TextColumn("ì œëª©", width="large"),
                "íšŒì‚¬": st.column_config.TextColumn("íšŒì‚¬", width="medium") if "íšŒì‚¬" in display_columns else None,
                "URL": st.column_config.LinkColumn("ğŸ”— ë§í¬", width="medium"),
                "ë‚ ì§œ": st.column_config.TextColumn("ë‚ ì§œ", width="small"),
                "ìš”ì•½": st.column_config.TextColumn("ìš”ì•½", width="large")
            }
        )
        
        # AI ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
        if hasattr(st.session_state, 'google_news_insight') and st.session_state.google_news_insight:
            st.markdown("---")
            st.subheader("ğŸ“‹ AI ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
            st.markdown(st.session_state.google_news_insight)
