# -*- coding: utf-8 -*-
from __future__ import annotations

import io
import json
import zipfile
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import Dict, List, Union

import feedparser
import pandas as pd
import requests
import streamlit as st
from dateutil import parser

# í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼ import
import config

# ì„ íƒì  ì˜ì¡´ì„± import
try:
    import gspread
    from google.oauth2.service_account import Credentials
    _GSPREAD_AVAILABLE = True
except ImportError:
    _GSPREAD_AVAILABLE = False


class DartAPICollector:
    """DART APIë¥¼ í†µí•´ ì¬ë¬´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, api_key):
        self.api_key = api_key
        self.source_tracking = {}
        self.company_name_mapping = config.COMPANY_NAME_MAPPING
        self.stock_code_mapping = config.STOCK_CODE_MAPPING

    def get_corp_code_enhanced(self, company_name):
        url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={self.api_key}"
        search_names = self.company_name_mapping.get(company_name, [company_name])
        
        try:
            res = requests.get(url)
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_file = z.open(z.namelist()[0])
                tree = ET.parse(xml_file)
                root = tree.getroot()
            
            all_companies = []
            for corp in root.findall("list"):
                corp_name_elem = corp.find("corp_name")
                corp_code_elem = corp.find("corp_code")
                stock_code_elem = corp.find("stock_code")
                
                if corp_name_elem is not None and corp_code_elem is not None:
                    all_companies.append({
                        'name': corp_name_elem.text,
                        'code': corp_code_elem.text,
                        'stock_code': stock_code_elem.text.strip() if stock_code_elem is not None and stock_code_elem.text else None
                    })
            
            for search_name in search_names:
                if search_name.isdigit(): # ì¢…ëª©ì½”ë“œë¡œ ê²€ìƒ‰
                    for company in all_companies:
                        if company['stock_code'] == search_name:
                            return company['code']
                
                for company in all_companies: # ì •í™•íˆ ì¼ì¹˜
                    if company['name'] == search_name:
                        return company['code']
            
            return None
        except Exception as e:
            st.error(f"íšŒì‚¬ ì½”ë“œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    def get_financial_statement(self, corp_code, bsns_year, reprt_code, fs_div="CFS"):
        url = "https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json"
        params = {
            "crtfc_key": self.api_key, "corp_code": corp_code, "bsns_year": bsns_year,
            "reprt_code": reprt_code, "fs_div": fs_div
        }
        try:
            res = requests.get(url, params=params).json()
            if res.get("status") == "000" and "list" in res:
                df = pd.DataFrame(res["list"])
                df["ë³´ê³ ì„œêµ¬ë¶„"] = reprt_code
                return df
            return pd.DataFrame()
        except Exception:
            return pd.DataFrame()

    def get_company_financials_auto(self, company_name, bsns_year):
        corp_code = self.get_corp_code_enhanced(company_name)
        if not corp_code:
            st.warning(f"DARTì—ì„œ '{company_name}'ì— ëŒ€í•œ ê³ ìœ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        report_codes = ["11011", "11014", "11012", "11013"] # ë…„ê°„ -> 3ë¶„ê¸° -> ë°˜ê¸° -> 1ë¶„ê¸° ìˆœ
        for report_code in report_codes:
            df = self.get_financial_statement(corp_code, str(bsns_year), report_code)
            if not df.empty:
                rcept_no = self._get_rcept_no(corp_code, str(bsns_year), report_code)
                self._save_source_info(company_name, corp_code, report_code, str(bsns_year), rcept_no)
                return df
        return None
    
    def _get_rcept_no(self, corp_code, bsns_year, report_code):
        # ì‹¤ì œ APIë¥¼ í†µí•´ ê°€ì¥ ìµœì‹  ë³´ê³ ì„œì˜ ì ‘ìˆ˜ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¡œì§ (ìƒ˜í”Œ)
        # í˜„ì¬ëŠ” ì‹œê°„ ê´€ê³„ìƒ ê°„ë‹¨í•œ í˜•íƒœë¡œ ëŒ€ì²´
        return f"{corp_code}_{bsns_year}_{report_code}_sample"

    def _save_source_info(self, company_name, corp_code, report_code, bsns_year, rcept_no):
        report_type_map = {
            "11011": "ì‚¬ì—…ë³´ê³ ì„œ", "11014": "3ë¶„ê¸°ë³´ê³ ì„œ",
            "11012": "ë°˜ê¸°ë³´ê³ ì„œ", "11013": "1ë¶„ê¸°ë³´ê³ ì„œ"
        }
        self.source_tracking[company_name] = {
            'company_code': corp_code, 'report_type': report_type_map.get(report_code, "ì¬ë¬´ì œí‘œ"),
            'year': bsns_year, 'rcept_no': rcept_no,
            'dart_url': f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
        }


class QuarterlyDataCollector:
    """ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, dart_collector: DartAPICollector):
        self.dart_collector = dart_collector
        # DART API ë¶„ê¸°ë³„ ë³´ê³ ì„œ ì½”ë“œ
        self.report_codes = {
            "Q1": "11013",  # 1ë¶„ê¸°ë³´ê³ ì„œ
            "Q2": "11012",  # ë°˜ê¸°ë³´ê³ ì„œ (2ë¶„ê¸° í¬í•¨)
            "Q3": "11014",  # 3ë¶„ê¸°ë³´ê³ ì„œ
            "Q4": "11011"   # ì‚¬ì—…ë³´ê³ ì„œ (4ë¶„ê¸° í¬í•¨)
        }
        # ë¶„ê¸°ë³„ ë³´ê³ ì„œëª… ë§¤í•‘
        self.quarter_names = {
            "Q1": "1ë¶„ê¸°ë³´ê³ ì„œ",
            "Q2": "ë°˜ê¸°ë³´ê³ ì„œ", 
            "Q3": "3ë¶„ê¸°ë³´ê³ ì„œ",
            "Q4": "ì‚¬ì—…ë³´ê³ ì„œ"
        }

    def collect_quarterly_data(self, company_name, year=2024):
        quarterly_results = []
        corp_code = self.dart_collector.get_corp_code_enhanced(company_name)
        if not corp_code:
            return pd.DataFrame()

        # ì§„í–‰ ìƒíƒœëŠ” ì¡°ìš©íˆ ì²˜ë¦¬ (ì‚¬ìš©ìì—ê²ŒëŠ” ìµœì¢… ê²°ê³¼ë§Œ í‘œì‹œ)
        for quarter, report_code in self.report_codes.items():
            report_name = self.quarter_names[quarter]
            
            df = self.dart_collector.get_financial_statement(corp_code, str(year), report_code)
            if not df.empty:
                metrics = self._extract_key_metrics(df, quarter, year)
                if metrics:
                    metrics['íšŒì‚¬'] = company_name
                    metrics['ì—°ë„'] = year
                    metrics['ë³´ê³ ì„œêµ¬ë¶„'] = report_name
                    quarterly_results.append(metrics)
                # ê°œë³„ ì§„í–‰ ë©”ì‹œì§€ ì œê±° - ì¡°ìš©íˆ ì²˜ë¦¬
            # ì‹¤íŒ¨ ë©”ì‹œì§€ë„ ì œê±° - ì¡°ìš©íˆ ì²˜ë¦¬
        
        # ìµœì¢… ê²°ê³¼ë§Œ ë°˜í™˜ (ì„±ê³µ/ì‹¤íŒ¨ ë©”ì‹œì§€ ì œê±°)
        return pd.DataFrame(quarterly_results) if quarterly_results else pd.DataFrame()

    def _extract_key_metrics(self, df, quarter, year):
        # ë¶„ê¸° í‘œì‹œë¥¼ ë” ëª…í™•í•˜ê²Œ (ì˜ˆ: 2024Q1, 2024Q2 ë“±)
        # Q4ì¼ ë•ŒëŠ” 2024ë¡œ í‘œì‹œ
        if quarter == "Q4":
            quarter_display = str(year)
        else:
            quarter_display = f"{year}{quarter}"
        metrics = {'ë¶„ê¸°': quarter_display}
        
        def find_amount(keywords):
            for keyword in keywords:
                rows = df[df['account_nm'].str.contains(keyword, case=False, na=False)]
                if not rows.empty:
                    try:
                        return float(str(rows.iloc[0]['thstrm_amount']).replace(',', '').replace('-', '0'))
                    except:
                        continue
            return 0

        # í•µì‹¬ ì¬ë¬´ì§€í‘œ ì¶”ì¶œ
        revenue = find_amount(['ë§¤ì¶œì•¡', 'revenue', 'sales'])
        cost_of_sales = find_amount(['ë§¤ì¶œì›ê°€', 'cost of sales', 'ë§¤ì¶œì›ê°€'])
        gross_profit = find_amount(['ë§¤ì¶œì´ì´ìµ', 'gross profit', 'ì´ì´ìµ'])
        operating_profit = find_amount(['ì˜ì—…ì´ìµ', 'operating profit', 'ì˜ì—…ì†ìµ'])
        net_income = find_amount(['ë‹¹ê¸°ìˆœì´ìµ', 'net income', 'ìˆœì´ìµ'])
        selling_expenses = find_amount(['íŒë§¤ë¹„', 'selling expenses'])
        administrative_expenses = find_amount(['ê´€ë¦¬ë¹„', 'administrative expenses'])
        sg_and_a = find_amount(['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„', 'íŒê´€ë¹„', 'selling and administrative'])

        # ê¸ˆì•¡ ë‹¨ìœ„ ë³€í™˜ ë° ì €ì¥
        if revenue > 0:
            metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] = revenue / 1_000_000_000_000
        if cost_of_sales > 0:
            metrics['ë§¤ì¶œì›ê°€(ì¡°ì›)'] = cost_of_sales / 1_000_000_000_000
        if gross_profit > 0:
            metrics['ë§¤ì¶œì´ì´ìµ(ì¡°ì›)'] = gross_profit / 1_000_000_000_000
        if operating_profit > 0:
            metrics['ì˜ì—…ì´ìµ(ì–µì›)'] = operating_profit / 100_000_000
        if net_income > 0:
            metrics['ë‹¹ê¸°ìˆœì´ìµ(ì–µì›)'] = net_income / 100_000_000
        if selling_expenses > 0:
            metrics['íŒë§¤ë¹„(ì–µì›)'] = selling_expenses / 100_000_000
        if administrative_expenses > 0:
            metrics['ê´€ë¦¬ë¹„(ì–µì›)'] = administrative_expenses / 100_000_000
        if sg_and_a > 0:
            metrics['íŒê´€ë¹„(ì–µì›)'] = sg_and_a / 100_000_000

        # ë¹„ìœ¨ ê³„ì‚°
        if 'ë§¤ì¶œì•¡(ì¡°ì›)' in metrics and 'ì˜ì—…ì´ìµ(ì–µì›)' in metrics and metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] > 0:
            metrics['ì˜ì—…ì´ìµë¥ (%)'] = (metrics['ì˜ì—…ì´ìµ(ì–µì›)'] * 100) / (metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] * 10_000)
        
        if 'ë§¤ì¶œì•¡(ì¡°ì›)' in metrics and 'ë§¤ì¶œì´ì´ìµ(ì¡°ì›)' in metrics and metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] > 0:
            metrics['ë§¤ì¶œì´ì´ìµë¥ (%)'] = (metrics['ë§¤ì¶œì´ì´ìµ(ì¡°ì›)'] / metrics['ë§¤ì¶œì•¡(ì¡°ì›)']) * 100
        
        if 'ë§¤ì¶œì•¡(ì¡°ì›)' in metrics and 'ë‹¹ê¸°ìˆœì´ìµ(ì–µì›)' in metrics and metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] > 0:
            metrics['ìˆœì´ìµë¥ (%)'] = (metrics['ë‹¹ê¸°ìˆœì´ìµ(ì–µì›)'] * 100) / (metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] * 10_000)
        
        if 'ë§¤ì¶œì•¡(ì¡°ì›)' in metrics and 'ë§¤ì¶œì›ê°€(ì¡°ì›)' in metrics and metrics['ë§¤ì¶œì•¡(ì¡°ì›)'] > 0:
            metrics['ë§¤ì¶œì›ê°€ìœ¨(%)'] = (metrics['ë§¤ì¶œì›ê°€(ì¡°ì›)'] / metrics['ë§¤ì¶œì•¡(ì¡°ì›)']) * 100
        
        return metrics if len(metrics) > 1 else None


class SKNewsCollector:
    """Google Sheetsì™€ RSSì—ì„œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, custom_keywords=None):
        self.sheet_id = config.SHEET_ID
        self.service_account_json = config.GOOGLE_SERVICE_ACCOUNT_JSON
        self.rss_feeds = config.DEFAULT_RSS_FEEDS
        self.oil_keywords = custom_keywords if custom_keywords else config.BENCHMARKING_KEYWORDS
        
        # ì •ìœ  íŠ¹í™” í‚¤ì›Œë“œ ë¶„ë¥˜ (ìš”ì²­ì‚¬í•­: (SKì—ë„ˆì§€ OR S-Oil OR HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ OR GSì¹¼í…ìŠ¤) AND (ì •ìœ ))
        self.company_keywords = ["SKì—ë„ˆì§€", "S-Oil", "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬", "GSì¹¼í…ìŠ¤"]
        self.industry_keywords = ["ì •ìœ ", "ì •ìœ ì—…ê³„", "ì •ìœ ì‚¬", "ì„ìœ í™”í•™", "ì—ë„ˆì§€ì‚°ì—…", "ì„ìœ ì‚°ì—…", "ì •ì œì—…", "ì •ì œê³µì •"]
        # self.business_keywords = ["ì˜ì—…ì´ìµ", "ì‹¤ì ", "ìˆ˜ìµì„±", "íˆ¬ì", "ë§¤ì¶œ", "ì†ì‹¤", "ì •ì œë§ˆì§„", "ì›ìœ ", "ë‚˜í”„íƒ€", "íœ˜ë°œìœ ", "ê²½ìœ ", "ì„ìœ ì œí’ˆ", "í™”í•™ì œí’ˆ", "ìœ ê°€", "WTI", "ë‘ë°”ì´ìœ ", "ë¸Œë ŒíŠ¸ìœ ", "ì„ìœ ê°€ê²©"]
        # self.trend_keywords = ["ì¹œí™˜ê²½", "íƒ„ì†Œì¤‘ë¦½", "ESG", "ì‹ ì¬ìƒì—ë„ˆì§€", "ìˆ˜ì†Œ", "ë°”ì´ì˜¤"]

    def collect_news(self, *, max_items_per_feed: int = 100) -> pd.DataFrame:
        df_sheets = self._fetch_sheet_news()
        df_rss = self._fetch_rss_news(max_items=max_items_per_feed)

        if df_sheets.empty and df_rss.empty:
            return pd.DataFrame()

        df_all = pd.concat([df_sheets, df_rss], ignore_index=True)
        df_all.drop_duplicates(subset="ì œëª©", keep="first", inplace=True)
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ ê°•í™”
        st.info(f"ğŸ” ì´ {len(df_all)}ê°œ ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§ ì¤‘...")
        df_all = self._filter_relevant_news(df_all)
        st.success(f"âœ… í•„í„°ë§ ì™„ë£Œ: {len(df_all)}ê°œ ê´€ë ¨ ë‰´ìŠ¤ ë°œê²¬")
        
        # í•„í„°ë§ëœ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì²˜ë¦¬
        if not df_all.empty:
            df_all = self._enrich_dataframe(df_all)
            
            # ê´€ë ¨ë„ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸)
            sort_columns = []
            if "ê´€ë ¨ë„ì ìˆ˜" in df_all.columns:
                sort_columns.append("ê´€ë ¨ë„ì ìˆ˜")
            if "SKê´€ë ¨ë„" in df_all.columns:
                sort_columns.append("SKê´€ë ¨ë„")
            if "ì˜í–¥ë„" in df_all.columns:
                sort_columns.append("ì˜í–¥ë„")
            
            if sort_columns:
                df_all.sort_values(sort_columns, ascending=[False] * len(sort_columns), inplace=True)
            
            # ìƒìœ„ 50ê°œë§Œ ë°˜í™˜ (í’ˆì§ˆ ìš°ì„ )
            return df_all.head(50).reset_index(drop=True)
        else:
            return pd.DataFrame()
    
    # ì´í•˜ _fetch_sheet_news, _fetch_rss_news, _enrich_dataframe ë“± ìƒì„¸ ë©”ì„œë“œëŠ” ì›ë³¸ ì½”ë“œì™€ ê±°ì˜ ë™ì¼
    # ì´ íŒŒì¼ì—ì„œëŠ” ìƒëµ. í•„ìš” ì‹œ ì›ë³¸ ì½”ë“œì˜ SKNewsCollector í´ë˜ìŠ¤ ë‚´ë¶€ ë©”ì„œë“œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬.
    # (ë„ˆë¬´ ê¸¸ì–´ì ¸ì„œ í•µì‹¬ ë¡œì§ë§Œ ë‚¨ê¹ë‹ˆë‹¤.)
    def _fetch_sheet_news(self) -> pd.DataFrame:
        if not _GSPREAD_AVAILABLE or not self.sheet_id or not self.service_account_json:
            return pd.DataFrame()
        try:
            creds = Credentials.from_service_account_info(self.service_account_json)
            gc = gspread.authorize(creds)
            worksheet = gc.open_by_key(self.sheet_id).sheet1
            rows = worksheet.get_all_records()
            return pd.DataFrame(rows)
        except Exception as e:
            st.warning(f"êµ¬ê¸€ ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def _fetch_rss_news(self, *, max_items: int = 50) -> pd.DataFrame:
        collected = []
        total_found = 0
        
        for source, url in self.rss_feeds.items():
            try:
                feed = feedparser.parse(url)
                source_count = 0
                
                for entry in feed.entries[:max_items]:
                    title = entry.get("title", "")
                    summary = entry.get("summary", "")
                    
                    # ì œëª©ê³¼ ìš”ì•½ì—ì„œ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
                    title = self._clean_text(title)
                    summary = self._clean_text(summary)
                    
                    # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    if len(title) < 5:
                        continue
                    
                    # 1ì°¨ í•„í„°ë§: ì œëª©ì—ì„œ ì •ìœ  ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸ (ì™„í™”)
                    title_lower = title.lower()
                    summary_lower = summary.lower()
                    full_text = f"{title_lower} {summary_lower}"
                    
                    # ë” ì™„í™”ëœ í•„í„°ë§: ì •ìœ  ê´€ë ¨ í‚¤ì›Œë“œë‚˜ íšŒì‚¬ëª…ì´ ìˆìœ¼ë©´ ìˆ˜ì§‘
                    has_oil_keyword = any(kw.lower() in full_text for kw in self.industry_keywords)
                    has_company_keyword = any(kw.lower() in full_text for kw in self.company_keywords)
                    has_business_keyword = any(kw.lower() in full_text for kw in ["ì˜ì—…ì´ìµ", "ì‹¤ì ", "ìˆ˜ìµì„±", "íˆ¬ì", "ë§¤ì¶œ", "ì†ì‹¤", "ì •ì œë§ˆì§„", "ì›ìœ ", "ë‚˜í”„íƒ€", "íœ˜ë°œìœ ", "ê²½ìœ ", "ì„ìœ ì œí’ˆ", "í™”í•™ì œí’ˆ", "ìœ ê°€", "WTI", "ë‘ë°”ì´ìœ ", "ë¸Œë ŒíŠ¸ìœ ", "ì„ìœ ê°€ê²©"])
                    
                    # ì •ìœ  ê´€ë ¨ í‚¤ì›Œë“œ, íšŒì‚¬ëª…, ë˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘
                    if has_oil_keyword or has_company_keyword or has_business_keyword:
                        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë‰´ìŠ¤ë§Œ ë¡œê·¸ ì¶œë ¥
                        if total_found == 0:
                            st.write(f"ğŸ” ì²« ë²ˆì§¸ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {title[:50]}...")
                        collected.append({
                            "ì œëª©": title,
                            "URL": entry.get("link", ""),
                            "ìš”ì•½": summary,
                            "ë‚ ì§œ": self._parse_date(entry.get("published", "")),
                            "ì¶œì²˜": source
                        })
                        source_count += 1
                        total_found += 1
                
                st.info(f"ğŸ“° {source}: {source_count}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ (ì´ {len(feed.entries)}ê°œ ê¸°ì‚¬ ì¤‘)")
                
            except Exception as e:
                st.warning(f"RSS í”¼ë“œ ìˆ˜ì§‘ ì˜¤ë¥˜ ({source}): {str(e)}")
                continue
        
        st.success(f"ğŸ¯ ì´ {total_found}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return pd.DataFrame(collected)
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ì „ì²˜ë¦¬"""
        if not text:
            return ""
        
        # HTML íƒœê·¸ ì œê±°
        import re
        text = re.sub(r'<[^>]+>', '', text)
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        text = re.sub(r'[^\w\sê°€-í£\-\.\,\!\?\(\)]', '', text)
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()

    def _filter_relevant_news(self, df: pd.DataFrame) -> pd.DataFrame:
        """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ë§Œ í•„í„°ë§ (ì •ìœ  íŠ¹í™” ê°•í™”)"""
        if df.empty:
            return df
        
        relevant_news = []
        for _, row in df.iterrows():
            title = str(row.get('ì œëª©', '')).lower()
            summary = str(row.get('ìš”ì•½', '')).lower()
            full_text = f"{title} {summary}"
            
            # ìš”ì²­ì‚¬í•­: (SKì—ë„ˆì§€ OR S-Oil OR HDí˜„ëŒ€ì˜¤ì¼ë±…í¬ OR GSì¹¼í…ìŠ¤) AND (ì •ìœ )
            # 1ë‹¨ê³„: í•µì‹¬ ì •ìœ ì‚¬ ì¤‘ í•˜ë‚˜ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_company = any(kw.lower() in full_text for kw in self.company_keywords)
            
            # 2ë‹¨ê³„: ì •ìœ  ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            has_oil_industry = any(kw.lower() in full_text for kw in self.industry_keywords)
            
            # 3ë‹¨ê³„: ì¶”ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œ í™•ì¸ (ê°€ì¤‘ì¹˜) (ì£¼ì„ì²˜ë¦¬)
            # business_matches = sum(1 for kw in self.business_keywords if kw.lower() in full_text)
            
            # í•„í„°ë§ ì¡°ê±´: ë” ì™„í™”ëœ ì¡°ê±´ìœ¼ë¡œ ë³€ê²½
            # ì •ìœ  ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜, íšŒì‚¬ëª…ì´ ìˆê±°ë‚˜, ë˜ëŠ” ê²½ì œ/ê¸°ì—… ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í¬í•¨
            has_economic_keyword = any(kw in full_text for kw in ["ê¸°ì—…", "ê²½ì œ", "ì£¼ì‹", "íˆ¬ì", "ë§¤ì¶œ", "ì‹¤ì ", "ì˜ì—…ì´ìµ", "ì‹œì¥", "ì¦ì‹œ"])
            
            if has_company or has_oil_industry or has_economic_keyword:
                relevant_news.append(row)
        
        return pd.DataFrame(relevant_news)

    def _enrich_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        if df.empty: 
            return df
        
        try:
            # íšŒì‚¬ ì»¬ëŸ¼ì€ ë°˜ë“œì‹œ ì¶”ê°€ (AI ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— í•„ìš”)
            df["íšŒì‚¬"] = df["ì œëª©"].apply(self._extract_company)
            
            # ì„ íƒì ìœ¼ë¡œ ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤ ì¶”ê°€
            df["í‚¤ì›Œë“œ"] = df["ì œëª©"].apply(self._extract_keywords)
            df["ì˜í–¥ë„"] = df["ì œëª©"].apply(self._calc_importance)
            df["SKê´€ë ¨ë„"] = df["ì œëª©"].apply(self._calc_sk_relevance)
            df["ê´€ë ¨ë„ì ìˆ˜"] = df.apply(self._calc_relevance_score, axis=1)
        except Exception as e:
            st.warning(f"ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì»¬ëŸ¼ ì¶”ê°€
            df["í‚¤ì›Œë“œ"] = ""
            df["ì˜í–¥ë„"] = 0
            df["íšŒì‚¬"] = "ê¸°íƒ€"
            df["SKê´€ë ¨ë„"] = 0
            df["ê´€ë ¨ë„ì ìˆ˜"] = 0
        
        return df

    def _extract_keywords(self, text: str) -> str:
        """ë” ì •í™•í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        text_lower = str(text).lower()
        found_keywords = []
        
        # íšŒì‚¬ëª… í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        for kw in self.company_keywords:
            if kw.lower() in text_lower:
                found_keywords.append(kw)
        
        # ì‚°ì—… í‚¤ì›Œë“œ
        for kw in self.industry_keywords:
            if kw.lower() in text_lower and kw not in found_keywords:
                found_keywords.append(kw)
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œ (ì£¼ì„ì²˜ë¦¬)
        # for kw in self.business_keywords:
        #     if kw.lower() in text_lower and kw not in found_keywords:
        #         found_keywords.append(kw)
        
        return ", ".join(found_keywords[:8])  # ìµœëŒ€ 8ê°œê¹Œì§€

    def _calc_importance(self, text: str) -> int:
        """ì˜í–¥ë„ ê³„ì‚° ê°œì„ """
        text_lower = str(text).lower()
        score = 0
        
        # í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
        business_terms = {
            "ì˜ì—…ì´ìµ": 3, "ì‹¤ì ": 3, "ì†ì‹¤": 3, "íˆ¬ì": 2, "ë§¤ì¶œ": 2,
            "ìˆ˜ìµì„±": 2, "ì‚¬ì—…í™•ì¥": 2, "ì›ê°€ì ˆê°": 2, "íš¨ìœ¨ì„±": 2
        }
        
        for term, weight in business_terms.items():
            if term in text_lower:
                score += weight
        
        return min(score, 10)

    def _calc_sk_relevance(self, text: str) -> int:
        """SK ê´€ë ¨ë„ ê³„ì‚° ê°œì„ """
        text_lower = str(text).lower()
        score = 0
        
        # SK ê´€ë ¨ í‚¤ì›Œë“œ
        if any(sk_term in text_lower for sk_term in ["sk", "ì—ìŠ¤ì¼€ì´", "skì—ë„ˆì§€", "skì´ë…¸ë² ì´ì…˜"]):
            score += 5
        
        # ì •ìœ /ì—ë„ˆì§€ ì‚°ì—… í‚¤ì›Œë“œ
        if any(term in text_lower for term in ["ì •ìœ ", "ì„ìœ ", "í™”í•™", "ì—ë„ˆì§€"]):
            score += 2
        
        # ê²½ìŸì‚¬ ê´€ë ¨ í‚¤ì›Œë“œ
        if any(comp in text_lower for comp in ["gsì¹¼í…ìŠ¤", "í˜„ëŒ€ì˜¤ì¼ë±…í¬", "s-oil", "ì—ì“°ì˜¤ì¼"]):
            score += 1
        
        return min(score, 10)

    def _calc_relevance_score(self, row) -> int:
        """ì¢…í•© ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""
        title = str(row.get('ì œëª©', '')).lower()
        summary = str(row.get('ìš”ì•½', '')).lower()
        full_text = f"{title} {summary}"
        
        score = 0
        
        # íšŒì‚¬ëª… ë§¤ì¹­ (ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜)
        for kw in self.company_keywords:
            if kw.lower() in full_text:
                score += 10
        
        # ì‚°ì—… í‚¤ì›Œë“œ ë§¤ì¹­
        for kw in self.industry_keywords:
            if kw.lower() in full_text:
                score += 3
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤ì›Œë“œ ë§¤ì¹­ (ì£¼ì„ì²˜ë¦¬)
        # for kw in self.business_keywords:
        #     if kw.lower() in full_text:
        #         score += 2
        
        # íŠ¸ë Œë“œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì£¼ì„ì²˜ë¦¬)
        # for kw in self.trend_keywords:
        #     if kw.lower() in full_text:
        #         score += 1
        
        return score

    def _extract_company(self, text: str) -> str:
        """íšŒì‚¬ëª… ì¶”ì¶œ ê°œì„ """
        text_lower = str(text).lower()
        
        # ì •í™•í•œ íšŒì‚¬ëª… ë§¤ì¹­
        company_mapping = {
            "skì—ë„ˆì§€": "SKì—ë„ˆì§€",
            "skì´ë…¸ë² ì´ì…˜": "SKì´ë…¸ë² ì´ì…˜", 
            "gsì¹¼í…ìŠ¤": "GSì¹¼í…ìŠ¤",
            "hdí˜„ëŒ€ì˜¤ì¼ë±…í¬": "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬",
            "í˜„ëŒ€ì˜¤ì¼ë±…í¬": "HDí˜„ëŒ€ì˜¤ì¼ë±…í¬",
            "s-oil": "S-Oil",
            "ì—ì“°ì˜¤ì¼": "S-Oil"
        }
        
        for key, value in company_mapping.items():
            if key in text_lower:
                return value
        
        return "ê¸°íƒ€"
    
    @staticmethod
    def _parse_date(date_str: str) -> str:
        try:
            return parser.parse(date_str).strftime("%Y-%m-%d %H:%M")
        except:
            return datetime.now().strftime("%Y-%m-%d %H:%M")