# -*- coding: utf-8 -*-
from __future__ import annotations

import re
import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup

_KRW_RE = re.compile(r'(krw|ì›|won)', re.IGNORECASE)

def _localname(qname: str) -> str:
    if not qname:
        return ''
    qname = qname.split('}')[-1]
    return qname.split(':')[-1].lower()

def _is_consolidated_context(ctx) -> bool | None:
    seg = ctx.find(lambda t: t.name and t.name.lower().endswith('segment'))
    if not seg:
        return None
    text = ' '.join([el.get_text(' ') for el in seg.find_all()])
    t = text.lower()
    if any(k in t for k in ['consolidated', 'ì—°ê²°', 'cfs', 'consolidatedmember', 'consolidatedgroupmember', 'dart:cfs']):
        return True
    if any(k in t for k in ['separate', 'ë³„ë„', 'separatemember', 'dart:separate']):
        return False
    return None


class FinancialDataProcessor:
    """ìˆ˜ë™ ì—…ë¡œë“œ XBRL â†’ ì—°ê²° ì†ìµê³„ì‚°ì„œì˜ ë¶„ê¸°(QTD) ê°’ìœ¼ë¡œ ì •ë¦¬"""

    # ì •í™• ë§¤í•‘(ë¡œì»¬ë„¤ì„ ìœ„ì£¼)
    CONCEPT_MAP = {
        'ë§¤ì¶œì•¡': [
            'ifrs-full:Revenue','revenue','sales','salesrevenue','operatingrevenue',
            'revenuefromcontractswithcustomers'
        ],
        'ë§¤ì¶œì›ê°€': ['costofsales','costofrevenue','costofgoodssold'],
        'ë§¤ì¶œì´ì´ìµ': ['grossprofit','grossincome'],
        'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„': ['sellinggeneraladministrativeexpenses','sellingandadministrativeexpenses','sga'],
        'ì˜ì—…ì´ìµ': ['profitlossfromoperatingactivities','operatingincome','operatingprofit'],
        'ë‹¹ê¸°ìˆœì´ìµ': ['profitloss','netincome','netprofit'],
        # ë³´ì¡° í•­ëª©
        'ì˜ì—…ì™¸ìˆ˜ìµ': ['nonoperatingincome','otherincome','financialincome'],
        'ì˜ì—…ì™¸ë¹„ìš©': ['nonoperatingexpense','otherexpense','financialcost','interestexpense']
    }

    # ë°±ì—…ìš© ì •ê·œì‹
    CONCEPT_REGEX = {
        'ë§¤ì¶œì•¡': r'(revenue|sales)$',
        'ë§¤ì¶œì›ê°€': r'(costofsales|costofrevenue|costofgoods)$',
        'ë§¤ì¶œì´ì´ìµ': r'(grossprofit)$',
        'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„': r'(selling.*administrative|sga$)',
        'ì˜ì—…ì´ìµ': r'(profitlossfromoperatingactivities|operatingprofit|operatingincome)$',
        'ë‹¹ê¸°ìˆœì´ìµ': r'(profitloss$|netincome$|netprofit$)',
    }

        # DART API í˜¸í™˜ ë§¤í•‘ (ê³„ì •ê³¼ëª© â†’ í‘œì¤€ í•­ëª©)
    INCOME_STATEMENT_MAP = {
        # ë§¤ì¶œ
        'revenue': 'ë§¤ì¶œì•¡', 'sales': 'ë§¤ì¶œì•¡', 'ë§¤ì¶œ': 'ë§¤ì¶œì•¡', 'ë§¤ì¶œì•¡': 'ë§¤ì¶œì•¡',
        'ì œí’ˆë§¤ì¶œ': 'ë§¤ì¶œì•¡', 'ìƒí’ˆë§¤ì¶œ': 'ë§¤ì¶œì•¡',
        # ë§¤ì¶œì›ê°€
        'costofgoodssold': 'ë§¤ì¶œì›ê°€', 'cogs': 'ë§¤ì¶œì›ê°€', 'costofsales': 'ë§¤ì¶œì›ê°€',
        'ë§¤ì¶œì›ê°€': 'ë§¤ì¶œì›ê°€', 'ì›ê°€': 'ë§¤ì¶œì›ê°€', 'ìƒí’ˆë§¤ì¶œì›ê°€': 'ë§¤ì¶œì›ê°€',
        # ë§¤ì¶œì´ì´ìµ
        'grossprofit': 'ë§¤ì¶œì´ì´ìµ', 'ë§¤ì¶œì´ì´ìµ': 'ë§¤ì¶œì´ì´ìµ', 'ì´ì´ìµ': 'ë§¤ì¶œì´ì´ìµ',
        # íŒê´€ë¹„
        'sellinggeneraladministrativeexpenses': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„',
        'sellingandadministrativeexpenses': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„',
        'sga': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„', 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„', 'íŒê´€ë¹„': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„',
        'íŒë§¤ê´€ë¦¬ë¹„': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„',
        # ì˜ì—…ì´ìµ
        'operatingincome': 'ì˜ì—…ì´ìµ', 'operatingprofit': 'ì˜ì—…ì´ìµ',
        'ì˜ì—…ì´ìµ': 'ì˜ì—…ì´ìµ', 'ì˜ì—…ì†ìµ': 'ì˜ì—…ì´ìµ',
        # ë‹¹ê¸°ìˆœì´ìµ
        'netincome': 'ë‹¹ê¸°ìˆœì´ìµ', 'netprofit': 'ë‹¹ê¸°ìˆœì´ìµ',
        'ë‹¹ê¸°ìˆœì´ìµ': 'ë‹¹ê¸°ìˆœì´ìµ', 'ìˆœì´ìµ': 'ë‹¹ê¸°ìˆœì´ìµ', 'ìˆœì†ìµ': 'ë‹¹ê¸°ìˆœì´ìµ',
        # ì„ íƒ: ì˜ì—…ì™¸ìˆ˜ìµ/ë¹„ìš©ë„ ìˆìœ¼ë©´ ë§¤í•‘
        'nonoperatingincome': 'ì˜ì—…ì™¸ìˆ˜ìµ', 'ê¸°íƒ€ìˆ˜ìµ': 'ì˜ì—…ì™¸ìˆ˜ìµ', 'ì˜ì—…ì™¸ìˆ˜ìµ': 'ì˜ì—…ì™¸ìˆ˜ìµ',
        'nonoperatingexpense': 'ì˜ì—…ì™¸ë¹„ìš©', 'ê¸°íƒ€ë¹„ìš©': 'ì˜ì—…ì™¸ë¹„ìš©', 'ì˜ì—…ì™¸ë¹„ìš©': 'ì˜ì—…ì™¸ë¹„ìš©',
    }

    def _parse_amount(self, s) -> float:
        """DART ê¸ˆì•¡ ë¬¸ìì—´ â†’ float (ê´„í˜¸=ìŒìˆ˜, ì½¤ë§ˆ ì œê±°)"""
        v = str(s or '').strip()
        if not v:
            return 0.0
        neg = '(' in v and ')' in v
        v = v.replace('(', '').replace(')', '').replace(',', '')
        try:
            num = float(v)
        except:
            num = 0.0
        return -num if neg else num

    def _norm(self, name: str) -> str:
        """ê³„ì •ê³¼ëª©ëª… ì •ê·œí™”(ì†Œë¬¸ì, ì˜/ìˆ«/í•œê¸€ë§Œ)"""
        return re.sub(r'[^a-z0-9ê°€-í£]', '', (name or '').lower())

    def process_dart_data(self, dart_df: pd.DataFrame, company_name: str) -> pd.DataFrame | None:
        """
        DART API ê²°ê³¼(DataFrame; ë³´í†µ account_nm, thstrm_amount ì»¬ëŸ¼)ë¥¼
        í‘œì¤€ ì†ìµê³„ì‚°ì„œ DataFrameìœ¼ë¡œ ë³€í™˜ (main_app í˜¸í™˜ìš©)
        """
        if dart_df is None or dart_df.empty:
            return None

        items: dict[str, float] = {}

        for _, row in dart_df.iterrows():
            raw_name = str(row.get('account_nm', '')).strip()
            amt = self._parse_amount(row.get('thstrm_amount', 0))

            if not raw_name:
                continue
            key = self._norm(raw_name)

            # ê°€ì¥ ê¸´ í‚¤ì›Œë“œê°€ ìš°ì„ ë˜ë„ë¡ ê¸¸ì´ìˆœ íƒìƒ‰
            best_std, best_len = None, -1
            for k, std in self.INCOME_STATEMENT_MAP.items():
                k_norm = self._norm(k)
                if k_norm and k_norm in key and len(k_norm) > best_len:
                    best_std, best_len = std, len(k_norm)

            if best_std:
                # ì¤‘ë³µ ê³„ì •ì€ ì ˆëŒ“ê°’ í° ê¸ˆì•¡ì„ ì±„íƒ
                if best_std not in items or abs(amt) > abs(items[best_std]):
                    items[best_std] = amt

        # íŒŒìƒ ê³„ì‚°
        if 'ë§¤ì¶œì´ì´ìµ' not in items and 'ë§¤ì¶œì•¡' in items and 'ë§¤ì¶œì›ê°€' in items:
            items['ë§¤ì¶œì´ì´ìµ'] = items['ë§¤ì¶œì•¡'] - items['ë§¤ì¶œì›ê°€']
        if 'ì˜ì—…ì´ìµ' not in items and 'ë§¤ì¶œì´ì´ìµ' in items and 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„' in items:
            items['ì˜ì—…ì´ìµ'] = items['ë§¤ì¶œì´ì´ìµ'] - items['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„']

        if not items:
            return None

        return self._build_statement(items, company_name)


    def __init__(self, debug: bool=False):
        self.debug = debug

    # ---------------- I/O ----------------

    def load_file(self, uploaded_file):
        try:
            size = uploaded_file.size if hasattr(uploaded_file, 'size') else 0
            if size > 50*1024*1024:
                st.error("âŒ 50MB ì´í•˜ íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                return None
            uploaded_file.seek(0)
            content = uploaded_file.read()
            xml = self._fast_decode(content)
            if not xml:
                st.error("âŒ íŒŒì¼ ì¸ì½”ë”©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            soup = self._safe_parse(xml)
            company = self._extract_company_name(soup, uploaded_file.name)

            facts = self._xbrl_to_facts(soup, company)
            if facts.empty:
                st.error("âŒ XBRL factë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None

            # report type: ìµœì‹  ì—°ë„ì˜ ìµœëŒ€ ì¢…ë£Œì›”ë¡œ íŒì •
            rpt = self._guess_report_type_by_month(facts)
            if self.debug:
                with st.expander("ğŸ§­ XBRL Context ë¶„ë¥˜ ë””ë²„ê·¸"):
                    latest_year = self._latest_duration_year(facts)
                    st.write(f"ReportType: {rpt}, LatestYear: {latest_year}")
                    sample = facts[['context_id','period_type','start','end']].drop_duplicates().head(20)
                    st.dataframe(sample, use_container_width=True)

            # ì—°ê²°+KRW+ëŒ€ìƒ ë¶„ê¸° ìœˆë„ìš°ë¡œ ìŠ¬ë¼ì´ìŠ¤ (ìµœì‹  ì—°ë„ ìš°ì„ )
            sliced = self._slice_to_quarter(facts, rpt)
            if sliced.empty:
                st.warning("âš ï¸ QTD ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª» ì°¾ì•„ì„œ YTD ë³´ì •/ë°±ì—… ìŠ¤ìºë„ˆë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
                sliced = self._slice_to_quarter_fallback(facts, rpt)

            items = self._facts_to_items(sliced)
            if not items:
                st.info("â„¹ï¸ facts ë§¤í•‘ ì‹¤íŒ¨ â†’ ë¬¸ì„œ íŒ¨í„´ ìŠ¤ìºë„ˆ ì‹œë„")
                items = self._backup_scan(soup)

            if not items:
                st.error("âŒ ì†ìµ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None

            df = self._build_statement(items, company)
            return df

        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    # ---------------- XML helpers ----------------

    def _safe_parse(self, content_str: str) -> BeautifulSoup:
        try:
            soup = BeautifulSoup(content_str, 'lxml-xml')
            if not soup.find():
                soup = BeautifulSoup(content_str, 'xml')
        except Exception:
            soup = BeautifulSoup(content_str, 'html.parser')
        return soup

    def _fast_decode(self, content: bytes) -> str | None:
        for enc in ['utf-8','utf-8-sig','cp949','euc-kr','iso-8859-1','ascii']:
            try:
                return content.decode(enc)
            except Exception:
                continue
        try:
            return content.decode('utf-8', errors='ignore')
        except Exception:
            return None

    def _extract_company_name(self, soup, filename):
        for t in ['EntityRegistrantName','CompanyName','ReportingEntityName','EntityName','CorporateName']:
            n = soup.find(t) or soup.find(lambda x: x.name and t.lower() in x.name.lower())
            if n and n.string and n.string.strip():
                return n.string.strip()
        name = (filename or '').split('.')[0].lower()
        mapping = {
            'sk':'SKì—ë„ˆì§€','skenergy':'SKì—ë„ˆì§€',
            'gs':'GSì¹¼í…ìŠ¤','gscaltex':'GSì¹¼í…ìŠ¤',
            'hd':'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬','hyundai':'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬','hdoil':'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬',
            's-oil':'S-Oil','soil':'S-Oil','soilcorp':'S-Oil'
        }
        for k,v in mapping.items():
            if k in name: return v
        clean = re.sub(r'[^A-Za-zê°€-í£0-9\s]','', name) or "Unknown Company"
        return clean

    # ---------------- Facts building ----------------

    def _xbrl_to_facts(self, soup: BeautifulSoup, company: str) -> pd.DataFrame:
        # contexts
        ctx_rows = []
        for c in soup.find_all(lambda t: t.name and t.name.lower().endswith('context')):
            cid = c.get('id')
            if not cid: continue
            period = c.find(lambda t: t.name and t.name.lower().endswith('period'))
            start = end = inst = None
            ptype = 'instant'
            if period:
                s = period.find(lambda t: t.name and t.name.lower().endswith('startdate'))
                e = period.find(lambda t: t.name and t.name.lower().endswith('enddate'))
                i = period.find(lambda t: t.name and t.name.lower().endswith('instant'))
                if s and s.text: start = s.text.strip()
                if e and e.text: end   = e.text.strip()
                if i and i.text: inst  = i.text.strip()
                if start and end: ptype = 'duration'
            ctx_rows.append({
                'context_id': cid,
                'period_type': ptype,
                'start': start,
                'end': end or inst,
                'is_consolidated': _is_consolidated_context(c),
            })
        ctx_df = pd.DataFrame(ctx_rows)
        if ctx_df.empty:
            return pd.DataFrame()

        ctx_df['start'] = pd.to_datetime(ctx_df['start'], errors='coerce')
        ctx_df['end']   = pd.to_datetime(ctx_df['end'], errors='coerce')

        # units
        units = {}
        for u in soup.find_all(lambda t: t.name and t.name.lower().endswith('unit')):
            uid = u.get('id')
            if not uid: continue
            m = u.find(lambda t: t.name and t.name.lower().endswith('measure'))
            units[uid] = (m.text.strip() if m and m.text else None)

        # facts
        rows = []
        facts = soup.find_all(lambda t: (t.name and (t.get('contextRef') or t.get('contextref'))))
        for el in facts:
            text = (el.text or '').strip()
            if not text: continue
            try:
                val = float(re.sub(r'[^\d\.-]', '', text.replace('(', '-').replace(')', '')))
            except Exception:
                continue
            cref = el.get('contextRef') or el.get('contextref')
            uref = el.get('unitRef')    or el.get('unitref')
            rows.append({
                'íšŒì‚¬': company,
                'concept_qname': el.name,
                'concept_local': _localname(el.name),
                'value': val,
                'unit': units.get(uref, uref),
                'context_id': cref,
            })
        df = pd.DataFrame(rows)
        if df.empty:
            return df

        df = df.merge(ctx_df, on='context_id', how='left')
        return df

    # ---- ìµœì‹  ì—°ë„/ë¶„ê¸° íŒì • ----
    def _latest_duration_year(self, facts: pd.DataFrame) -> int:
        dur = facts[facts['period_type'] == 'duration'].copy()
        ends = dur['end'].dropna()
        if ends.empty:
            # ì•ˆì „ì¥ì¹˜: ì „ë¶€ instantë©´ í˜„ì¬ ì—°ë„ ì‚¬ìš©
            return pd.Timestamp.today().year
        return int(ends.max().year)

    def _guess_report_type_by_month(self, facts: pd.DataFrame) -> str:
        dur = facts[facts['period_type']=='duration'].copy()
        if dur['end'].notna().any():
            latest_end = dur['end'].max()
            return {3:'Q1',6:'Q2',9:'Q3',12:'Q4'}.get(int(latest_end.month),'Q3')
        return 'Q3'

    # ------------- Quarter slicing -------------
    def _slice_to_quarter(self, facts: pd.DataFrame, report_type: str) -> pd.DataFrame:
        # 1) ìµœì‹  ì—°ë„ ë¨¼ì € ê²°ì • (í•„í„° ì ìš© ì „ì—)
        latest_year = self._latest_duration_year(facts)

        # 2) KRW & ì—°ê²° ìš°ì„  í•„í„°
        f = facts.copy()
        if 'unit' in f.columns:
            f = f[f['unit'].astype(str).str.contains(_KRW_RE, na=False)]
        if 'is_consolidated' in f.columns and f['is_consolidated'].notna().any():
            cfs = f['is_consolidated'] == True
            if cfs.any(): f = f[cfs]

        # 3) ìµœì‹  ì—°ë„ë§Œ ë‚¨ê¸°ê¸° (í•„í„° í›„ ë¹„ì—ˆë‹¤ë©´, í•„í„° ì—†ì´ ì—°ë„ë§Œ ì œí•œ)
        f_year = f[(f['period_type']=='duration') & (f['end'].dt.year == latest_year)].copy()
        if f_year.empty:
            f_year = facts[(facts['period_type']=='duration') & (facts['end'].dt.year == latest_year)].copy()

        if f_year.empty:
            return pd.DataFrame()

        def pick(frame, start_m, end_m):
            m = (frame['start'].dt.month==start_m) & (frame['end'].dt.month==end_m)
            return frame[m]

        # QTD ìš°ì„ ìˆœìœ„
        if report_type=='Q1':
            qtd = pick(f_year, 1,3)
            ytd = pick(f_year, 1,3)  # Q1ì€ YTD==QTD
            prev = pd.DataFrame()
        elif report_type=='Q2':
            qtd = pick(f_year, 4,6)
            ytd = pick(f_year, 1,6)
            prev = pick(f_year, 1,3)
            if qtd.empty and not ytd.empty and not prev.empty:
                qtd = self._diff(ytd, prev)
        elif report_type=='Q3':
            qtd = pick(f_year, 7,9)
            ytd = pick(f_year, 1,9)
            prev = pick(f_year, 1,6)
            if qtd.empty and not ytd.empty and not prev.empty:
                qtd = self._diff(ytd, prev)
        else:  # Q4
            qtd = pick(f_year, 10,12)
            ytd = pick(f_year, 1,12)
            prev = pick(f_year, 1,9)
            if qtd.empty and not ytd.empty and not prev.empty:
                qtd = self._diff(ytd, prev)

        if self.debug:
            with st.expander("ğŸ” ìµœì‹ ì—°ë„ ìŠ¬ë¼ì´ìŠ¤ ë””ë²„ê·¸"):
                st.write(f"LatestYear={latest_year}, ReportType={report_type}")
                st.write(f"Rows(QTD)={len(qtd)}, Rows(YTD)={len(ytd) if 'ytd' in locals() else 0}")

        return qtd

    def _slice_to_quarter_fallback(self, facts: pd.DataFrame, report_type: str) -> pd.DataFrame:
        """ì»¨í…ìŠ¤íŠ¸ id ë¬¸ìì—´ íŒ¨í„´ + ìµœì‹ ì—°ë„ ì œí•œ ë³´ì¡° ì„ íƒ"""
        latest_year = self._latest_duration_year(facts)
        dur = facts[(facts['period_type']=='duration') & (facts['end'].dt.year==latest_year)].copy()
        if dur.empty:
            return dur
        if report_type=='Q3':
            pat = re.compile(r'(7.?01|07.?01).*(9.?30|09.?30)')
        elif report_type=='Q2':
            pat = re.compile(r'(4.?01|04.?01).*(6.?30|06.?30)')
        elif report_type=='Q1':
            pat = re.compile(r'(1.?01|01.?01).*(3.?31|03.?31)')
        else:
            pat = re.compile(r'(10.?01).*(12.?31)')
        mask = dur['context_id'].astype(str).str.contains(pat, regex=True, na=False)
        return dur[mask]

    def _diff(self, ytd: pd.DataFrame, prev: pd.DataFrame) -> pd.DataFrame:
        """ë™ì¼ concept/local ê¸°ì¤€ìœ¼ë¡œ ytd - prev ì°¨ê°"""
        y = ytd[['concept_local','concept_qname','value','unit','context_id','start','end']].copy()
        p = prev[['concept_local','value']].rename(columns={'value':'prev'}).copy()
        out = y.merge(p, on='concept_local', how='left')
        out['value'] = out['value'] - out['prev'].fillna(0)
        out = out.drop(columns=['prev'])
        out['context_id'] = out['context_id'].astype(str) + '_QTD'
        return out

    # ------------- Mapping to items -------------
    def _facts_to_items(self, df: pd.DataFrame) -> dict:
        if df is None or df.empty:
            return {}
        items = {}

        # 1) ì •í™• ë§¤í•‘(ì—¬ëŸ¬ í›„ë³´ ì¤‘ ì ˆëŒ“ê°’ í° ê°’)
        for std, cands in self.CONCEPT_MAP.items():
            vals = []
            for q in cands:
                key = _localname(q)
                vals.append(df[df['concept_local']==key]['value'])
            s = pd.concat(vals) if vals else pd.Series(dtype=float)
            if not s.empty:
                v = s.reindex(s.abs().sort_values(ascending=False).index).iloc[0]
                items[std] = float(v)

        # 2) ì •ê·œì‹ ë³´ê°•
        for std, rx in self.CONCEPT_REGEX.items():
            if std in items: continue
            m = df['concept_local'].str.contains(rx, regex=True, na=False)
            if m.any():
                s = df.loc[m, 'value']
                v = s.reindex(s.abs().sort_values(ascending=False).index).iloc[0]
                items[std] = float(v)

        # íŒŒìƒ
        if 'ë§¤ì¶œì´ì´ìµ' not in items and 'ë§¤ì¶œì•¡' in items and 'ë§¤ì¶œì›ê°€' in items:
            items['ë§¤ì¶œì´ì´ìµ'] = items['ë§¤ì¶œì•¡'] - items['ë§¤ì¶œì›ê°€']
        if 'ì˜ì—…ì´ìµ' not in items and 'ë§¤ì¶œì´ì´ìµ' in items and 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„' in items:
            items['ì˜ì—…ì´ìµ'] = items['ë§¤ì¶œì´ì´ìµ'] - items['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„']

        return items

    # ------------- Backup scanner -------------
    def _backup_scan(self, soup: BeautifulSoup) -> dict:
        items, processed = {}, 0
        numeric = [t for t in soup.find_all() if t.string and re.search(r'\d', t.string)]
        for tag in numeric:
            txt = tag.string.strip()
            try:
                num = float(re.sub(r'[^\d\.-]', '', txt.replace('(', '-').replace(')', '')))
            except Exception:
                continue
            if abs(num) < 10000:
                continue
            parts = [tag.name.lower() if tag.name else '']
            if tag.attrs:
                parts.extend([str(v).lower() for v in tag.attrs.values()])
            if tag.parent and tag.parent.name:
                parts.append(tag.parent.name.lower())
            info = ' '.join(parts)
            for rx, std in {
                r'(revenue|sales)(?!.*cost)': 'ë§¤ì¶œì•¡',
                r'(cost.*(sales|goods))|ë§¤ì¶œì›ê°€|ì›ê°€': 'ë§¤ì¶œì›ê°€',
                r'(gross.*profit|ë§¤ì¶œì´ì´ìµ)': 'ë§¤ì¶œì´ì´ìµ',
                r'(selling.*administrative|íŒê´€ë¹„|íŒë§¤ë¹„.*ê´€ë¦¬ë¹„)': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„',
                r'(operating.*(income|profit)|ì˜ì—…ì´ìµ)': 'ì˜ì—…ì´ìµ',
                r'(profitloss$|netincome$|netprofit$|ë‹¹ê¸°ìˆœì´ìµ)': 'ë‹¹ê¸°ìˆœì´ìµ'
            }.items():
                if re.search(rx, info, re.IGNORECASE):
                    if std not in items or abs(num) > abs(items[std]):
                        items[std] = num
        return items

    # ------------- Statement / ratios / merge -------------
    def _build_statement(self, data: dict, company: str) -> pd.DataFrame:
        order = ['ë§¤ì¶œì•¡','ë§¤ì¶œì›ê°€','ë§¤ì¶œì´ì´ìµ','íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„','ì˜ì—…ì´ìµ','ì˜ì—…ì™¸ìˆ˜ìµ','ì˜ì—…ì™¸ë¹„ìš©','ë‹¹ê¸°ìˆœì´ìµ']
        rows = []
        for k in order:
            if k in data:
                rows.append({'êµ¬ë¶„': k, company: self._fmt_amt(data[k]), f'{company}_ì›ì‹œê°’': data[k]})
        sales = data.get('ë§¤ì¶œì•¡', 0)
        if sales:
            def r(name, num): rows.append({'êµ¬ë¶„': name, company: f"{(num/sales)*100:.2f}%", f'{company}_ì›ì‹œê°’': (num/sales)*100})
            if 'ì˜ì—…ì´ìµ' in data: r('ì˜ì—…ì´ìµë¥ (%)', data['ì˜ì—…ì´ìµ'])
            if 'ë§¤ì¶œì´ì´ìµ' in data: r('ë§¤ì¶œì´ì´ìµë¥ (%)', data['ë§¤ì¶œì´ì´ìµ'])
            if 'ë‹¹ê¸°ìˆœì´ìµ' in data: r('ìˆœì´ìµë¥ (%)', data['ë‹¹ê¸°ìˆœì´ìµ'])
            if 'ë§¤ì¶œì›ê°€' in data: r('ë§¤ì¶œì›ê°€ìœ¨(%)', data['ë§¤ì¶œì›ê°€'])
            if 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„' in data: r('íŒê´€ë¹„ìœ¨(%)', data['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„'])
        return pd.DataFrame(rows)

    def _fmt_amt(self, v: float) -> str:
        if v == 0: return "0ì›"
        sign = "â–¼ " if v < 0 else ""
        a = abs(v)
        if a >= 1_000_000_000_000: return f"{sign}{v/1_000_000_000_000:.1f}ì¡°ì›"
        if a >= 100_000_000:        return f"{sign}{v/100_000_000:.0f}ì–µì›"
        if a >= 10_000:             return f"{sign}{v/10_000:.0f}ë§Œì›"
        return f"{sign}{v:,.0f}ì›"

    def merge_company_data(self, dataframes: list[pd.DataFrame]):
        if not dataframes: return pd.DataFrame()
        if len(dataframes) == 1: return dataframes[0]
        merged = dataframes[0].copy()
        for df in dataframes[1:]:
            try:
                cols = [c for c in df.columns if c != 'êµ¬ë¶„' and not c.endswith('_ì›ì‹œê°’')]
                for c in cols:
                    merged = merged.set_index('êµ¬ë¶„').join(df.set_index('êµ¬ë¶„')[c], how='outer').reset_index()
            except Exception as e:
                st.warning(f"âš ï¸ ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")
        return merged.fillna("-")

# --- backward compatibility shim ---
SKFinancialDataProcessor = FinancialDataProcessor
__all__ = ["FinancialDataProcessor", "SKFinancialDataProcessor"]

